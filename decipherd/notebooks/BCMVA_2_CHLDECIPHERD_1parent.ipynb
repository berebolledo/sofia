{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python modules\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires the following databses\n",
    "# phenotypes_db.txt : database of genes and known phenotypes associations\n",
    "# mim2gene_mod.txt : gene mim ID\n",
    "# pLI.gnomad.txt : gnomad pLI calculation per gene\n",
    "localfiles = \"/Users/boris/GoogleDrive/UDD/research/bioinformatics/SABIO/projects/01_DECIPHERD/00_run_pipeline/\"\n",
    "phenotypes_db = localfiles + \"/databases/phenotypes_db.txt\"\n",
    "mim2gene_db = localfiles + \"/databases/mim2gene_mod.txt\"\n",
    "#pLI_db = localfiles + \"/databases/pLI.gnomad.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input/ouput \n",
    "timestamp = str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\"))\n",
    "\n",
    "decipherd = \"/Users/boris/GoogleDrive/UDD/research/bioinformatics/SABIO/projects/01_DECIPHERD/\"\n",
    "baylorva = \"baylor/LABWORK/exome_analysis/\"\n",
    "\n",
    "famid = \"BH13053\"\n",
    "proband = famid + \"-1\" + \"_filtered_reannotated.csv\"\n",
    "outband = famid + \"-1\" + \"_decipherd.xlsx\"\n",
    "\n",
    "infile = decipherd+baylorva+proband\n",
    "outfile = decipherd+baylorva+timestamp+\"_\"+outband\n",
    "\n",
    "# Define comparison file\n",
    "parent = decipherd + baylorva + famid + \"-2\" + \"_filtered_reannotated.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function takes frequency values. If frequency values exist, they are compared to the AF<=0.01, otherwise, if\n",
    "# no info is available, keep the site anyway\n",
    "def freq_check(values, NotANum):\n",
    "    outvals = [str(v) for v in values]\n",
    "    results = 0\n",
    "    for freq in values:\n",
    "        if freq is NotANum:\n",
    "            freq2 = 0\n",
    "        else:\n",
    "            freq2 = freq\n",
    "        try:\n",
    "            f = float(freq2)\n",
    "            if f <= 0.015:\n",
    "                results+-1\n",
    "            else:\n",
    "                results+=1\n",
    "        except:\n",
    "            results+=0\n",
    "    if results <= 0:\n",
    "        return pd.Series([\"rare|unknown\", \"|\".join(outvals)])\n",
    "    else:\n",
    "        return pd.Series([\"common\", \"|\".join(outvals)])\n",
    "\n",
    "# The function takes impact values. If impact values exist, at least two criteria agree with functional impact, otherwise, if\n",
    "# no info is available, keep the site anyway\n",
    "def impact_check(values, NotANum):\n",
    "    outvals = [str(v) for v in values]\n",
    "    results = 0\n",
    "    for impact in values:\n",
    "        if impact is NotANum:\n",
    "            imp2 = \"D\"\n",
    "        else:\n",
    "            imp2 = impact\n",
    "        try:\n",
    "            i = str(imp2)\n",
    "            if i in [\"D\", \"P\", \"H\", \"M\", \"A\"]:\n",
    "                results+=-1\n",
    "            elif i != '.':\n",
    "                results+=1\n",
    "            else:\n",
    "                results+=0\n",
    "        except:\n",
    "            results+=0\n",
    "    if results <= 0:\n",
    "        return pd.Series([\"affecting|unknown\", \"|\".join(outvals)])\n",
    "    else:\n",
    "        return pd.Series([\"unaffecting\", \"|\".join(outvals)])\n",
    "\n",
    "# This function check for DP of the variant call >=50\n",
    "def check_DP(depth, cutoff=50):\n",
    "    #dp = depth.strip().split(\":\")[2]\n",
    "    dp = depth\n",
    "    if float(dp) >= cutoff:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# This function check for GT \n",
    "def check_GT(genotype, gt_default='1/1'):\n",
    "    gt = genotype.strip().split(\":\")[0]\n",
    "    if gt == gt_default:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# This function splits DP and GT \n",
    "def split_format(fmt, n):\n",
    "    out = fmt.strip().split(\":\")[n]\n",
    "    if n in [2,3]:\n",
    "        return int(out)\n",
    "    else:\n",
    "        return out\n",
    "\n",
    "# Determine zygosity\n",
    "def zygosity(genotype):\n",
    "    A1,A2 = genotype.split(\"/\")\n",
    "    if A1==A2:\n",
    "        return \"hom\"\n",
    "    else:\n",
    "        return \"het\"\n",
    "\n",
    "def compound(genes, gene_occ):\n",
    "    gene_list = str(genes).split(',')\n",
    "    occurence = [gene_occ[gene] for gene in gene_list]\n",
    "    if len([i for i in occurence if i>1]) !=0:\n",
    "        return 'true'\n",
    "    else:\n",
    "        return 'false'\n",
    "\n",
    "def pheno_dic(entry):\n",
    "    genes = entry[0]\n",
    "    pheno = entry[1]\n",
    "    for gene in genes.split(','):\n",
    "        return (gene,pheno)\n",
    "\n",
    "def get_pheno(genes,phenodb):\n",
    "    phenotypes = []\n",
    "    for gene in str(genes).split(','):\n",
    "        try:\n",
    "            phenotypes.append(phenodb[gene])\n",
    "        except:\n",
    "            pass\n",
    "    return ''.join(list(set(phenotypes)))\n",
    "\n",
    "def get_info(info, val):\n",
    "    info_values = info.split(';')\n",
    "    tmp = [i for i in info_values if i.startswith(val)]\n",
    "    try:\n",
    "        out = float(tmp[0].split(\"=\")[1])\n",
    "    except:\n",
    "        out = ''\n",
    "    return out\n",
    "\n",
    "def check_gene(genes, db):\n",
    "    genelist =  str(genes).split(',')\n",
    "    match = [g for g in genelist if g in db.keys()]\n",
    "    if match:\n",
    "        n, feat, hpo = pheno_db[match[0]]\n",
    "        return pd.Series([\"yes\", n, feat, hpo])\n",
    "    else:\n",
    "        return pd.Series([\"no\",0,'-','-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read genomic data table generated by uploading HC-GATK raw VCF to http://wannovar.wglab.org/ \n",
    "data = pd.read_csv(infile, low_memory=False)\n",
    "parent = pd.read_csv(parent, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add MIM phenotypes info\n",
    "pheno_0 = pd.read_csv(phenotypes_db, header=None, sep='\\t')\n",
    "pheno_0.columns = ['Raw_gene_name','Phenotypes']\n",
    "pheno_1 = pheno_0.dropna()\n",
    "phenodbase = dict(list(pheno_1.apply(pheno_dic, axis=1)))\n",
    "data[\"Phenotypes\"] = data['Raw_gene_name'].apply(get_pheno, phenodb=phenodbase)\n",
    "\n",
    "del pheno_0\n",
    "del pheno_1\n",
    "del phenotypes_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add MIM gene info\n",
    "omim = pd.read_csv(mim2gene_db, low_memory=False, header=None, sep='\\t')\n",
    "omim.columns = ['mim', 'Raw_gene_name']\n",
    "weblinks = omim.mim.apply(lambda x: '=HYPERLINK(\"https://www.omim.org/entry/%s\", \"%s\")' % (str(x), str(x)))\n",
    "omim['mim'] = weblinks\n",
    "data_2 = pd.merge(data, omim, how = 'left')\n",
    "\n",
    "del omim\n",
    "del mim2gene_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "data = data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Snp = []\n",
    "for snp, chrom, pos, ref,alt in data[['DBSNP_rsid', 'CHROM','POS','REF','ALT']].values:\n",
    "#    if str(snp) != 'nan':\n",
    "#        Snp.append('=HYPERLINK(\"https://www.ncbi.nlm.nih.gov/snp/%s\", \"%s\")' % (snp, snp))\n",
    "#    else:\n",
    "        loc = \"%s:%s%s>%s\" % (chrom,pos,ref,alt)\n",
    "        Snp.append('=HYPERLINK(\"https://gnomad.broadinstitute.org/region/%s-%s-%s\", \"%s\")' % (chrom,pos,pos,loc))\n",
    "\n",
    "data['Gnomad'] = Snp       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "marrvel = []\n",
    "for chrom, pos, ref, alt in data[['CHROM','POS','REF','ALT']].values:\n",
    "    loc = \"%s:%s%%20%s>%s\" % (chrom,pos,ref,alt)\n",
    "    marrvel.append('=HYPERLINK(\"http://marrvel.org/search/variant/%s\", \"%s\")' % (loc,loc))\n",
    "data['marrvel'] = marrvel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract frequency databases column names\n",
    "freq_cols_tmp = [col for col in list(data.columns) if col.endswith(\"_ALL\") or col.endswith(\"_all\")]\n",
    "freq_cols = [freq_cols_tmp[i] for i in [0,2,3,4]]\n",
    "\n",
    "# Extract Clinvar column\n",
    "#clinVar_cols = [col for col in list(data.columns) if col.startswith(\"ClinVar\")][1:]\n",
    "clinVar_cols = [\"CLNSIG\"]\n",
    "\n",
    "# Define impact criterias to be considered\n",
    "impact_cols = [\"SIFT_pred\", \"Polyphen2_HDIV_pred\", \"Polyphen2_HVAR_pred\", \n",
    "               \"MutationTaster_pred\", \"MutationAssessor_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_freq = data[freq_cols].apply(freq_check, axis=1, NotANum=np.nan)\n",
    "allele_freq.columns = [\"db_AF_class\", \"db_AF_class_values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp = pd.concat([data,allele_freq], axis=1)\n",
    "data = data_tmp\n",
    "del data_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_effect = data[impact_cols].apply(impact_check, axis=1, NotANum=np.nan)\n",
    "pred_effect.columns = [\"pred_effect_class\", \"pred_effect_class_values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp = pd.concat([data,pred_effect], axis=1)\n",
    "data = data_tmp\n",
    "del data_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Parent'] = list(data['key'].str.replace(\"-1_\", \"-2_\").isin(parent['key']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "getcols = [\"Zygosity\", \"Compound_het\", \"Potential_Denovo\", \"Potential_InTrans\", \n",
    "           \"Potential_InCis\", \"Potential_Parent1\", \"Potential_Parent2\",\n",
    "          \"Raw_gene_name\", \"Mutation_type_.Refseq.\", \"Mutation_type_.UCSC.\", \"pLI\", \"CADD_phred\"]\n",
    "\n",
    "uddcols = list(data.columns)[175:]\n",
    "bcmcols = [col for col in list(data.columns)[:175] if col not in getcols]\n",
    "\n",
    "#outcols = [\"BR_filter\"] + [\"Parent\"] + uddcols + getcols + bcmcols \n",
    "outcols = uddcols + ['ARO'] + getcols + bcmcols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "data.CHROM.replace(['X','Y'],[23,24], inplace=True)\n",
    "tmp = pd.to_numeric(data.CHROM)\n",
    "data.drop('CHROM',axis=1)\n",
    "data['CHROM'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.to_numeric(data.pLI.replace('nan', '-1'))\n",
    "data['pLI'] = tmp\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.to_numeric(data.CADD_phred.replace('.', '-1'))\n",
    "data['CADD_phred'] = tmp\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['CHROM','POS'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "data['ARO'] = data.Phenotypes.str.contains('recessive') & ~(data.Phenotypes.str.contains('dominant'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(outfile)\n",
    "data[outcols].to_excel(writer, famid+\"-1\", index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
