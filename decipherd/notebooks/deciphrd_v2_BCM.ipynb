{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python modules\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires the following databses\n",
    "# phenotypes_db.txt : database of genes and known phenotypes associations\n",
    "# mim2gene_mod.txt : gene mim ID\n",
    "# pLI.gnomad.txt : gnomad pLI calculation per gene\n",
    "localfiles = \"/Users/boris/GoogleDrive/UDD/research/bioinformatics/SABIO/projects/01_DECIPHERD/00_run_pipeline/\"\n",
    "phenotypes_db = localfiles + \"/databases/phenotypes_db.txt\"\n",
    "mim2gene_db = localfiles + \"/databases/mim2gene_mod.txt\"\n",
    "pLI_db = localfiles + \"/databases/pLI.gnomad.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "timestamp = str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\"))\n",
    "run = 'run004'\n",
    "prefix = \"UDD034\"\n",
    "inputdir = localfiles + \"/\" + run + \"/\" + prefix + \"_inputfiles/\"\n",
    "outdir = localfiles + \"/\" + run + \"/\" + prefix + \"_\" + timestamp + \"/\"\n",
    "wannovar_file = inputdir + prefix + \"_annovar.txt\"\n",
    "intervar_file = inputdir + prefix + \"_intervar.txt\"\n",
    "phenotips_file = inputdir + prefix + \"_phenotips.tsv\"\n",
    "sophia_file = inputdir + prefix + \"_sophia.xls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function takes frequency values. If frequency values exist, they are compared to the AF<=0.01, otherwise, if\n",
    "# no info is available, keep the site anyway\n",
    "def freq_check(values, NotANum):\n",
    "    results = 0\n",
    "    for freq in values:\n",
    "        if freq is NotANum:\n",
    "            freq2 = 0\n",
    "        else:\n",
    "            freq2 = freq\n",
    "        try:\n",
    "            f = float(freq2)\n",
    "            if f <= 0.01:\n",
    "                results+-1\n",
    "            else:\n",
    "                results+=1\n",
    "        except:\n",
    "            results+=0\n",
    "    if results <= 0:\n",
    "        return \"rare|unknown\"\n",
    "    else:\n",
    "        return \"common\"\n",
    "\n",
    "# The function takes impact values. If impact values exist, at least two criteria agree with functional impact, otherwise, if\n",
    "# no info is available, keep the site anyway\n",
    "def impact_check(values, NotANum):\n",
    "    results = 0\n",
    "    for impact in values:\n",
    "        if impact is NotANum:\n",
    "            imp2 = \"D\"\n",
    "        else:\n",
    "            imp2 = impact\n",
    "        try:\n",
    "            i = str(imp2)\n",
    "            if i in [\"D\", \"P\", \"H\", \"M\", \"A\"]:\n",
    "                results+=-1\n",
    "            else:\n",
    "                results+=1\n",
    "        except:\n",
    "            results+=0\n",
    "    if results <= 0:\n",
    "        return \"affected|unknown\"\n",
    "    else:\n",
    "        return \"unaffected\"\n",
    "\n",
    "# This function check for DP of the variant call >=50\n",
    "def check_DP(depth, cutoff=50):\n",
    "    #dp = depth.strip().split(\":\")[2]\n",
    "    dp = depth\n",
    "    if float(dp) >= cutoff:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# This function check for GT \n",
    "def check_GT(genotype, gt_default='1/1'):\n",
    "    gt = genotype.strip().split(\":\")[0]\n",
    "    if gt == gt_default:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# This function splits DP and GT \n",
    "def split_format(fmt, n):\n",
    "    out = fmt.strip().split(\":\")[n]\n",
    "    if n in [2,3]:\n",
    "        return int(out)\n",
    "    else:\n",
    "        return out\n",
    "\n",
    "# Determine zygosity\n",
    "def zygosity(genotype):\n",
    "    A1,A2 = genotype.split(\"/\")\n",
    "    if A1==A2:\n",
    "        return \"hom\"\n",
    "    else:\n",
    "        return \"het\"\n",
    "\n",
    "def compound(genes, gene_occ):\n",
    "    gene_list = str(genes).split(',')\n",
    "    occurence = [gene_occ[gene] for gene in gene_list]\n",
    "    if len([i for i in occurence if i>1]) !=0:\n",
    "        return 'true'\n",
    "    else:\n",
    "        return 'false'\n",
    "\n",
    "def pheno_dic(entry):\n",
    "    genes = entry[0]\n",
    "    pheno = entry[1]\n",
    "    for gene in genes.split(','):\n",
    "        return (gene,pheno)\n",
    "\n",
    "def get_pheno(genes,phenodb):\n",
    "    phenotypes = []\n",
    "    for gene in str(genes).split(','):\n",
    "        try:\n",
    "            phenotypes.append(phenodb[gene])\n",
    "        except:\n",
    "            pass\n",
    "    return ''.join(list(set(phenotypes)))\n",
    "\n",
    "def get_info(info, val):\n",
    "    info_values = info.split(';')\n",
    "    tmp = [i for i in info_values if i.startswith(val)]\n",
    "    try:\n",
    "        out = float(tmp[0].split(\"=\")[1])\n",
    "    except:\n",
    "        out = ''\n",
    "    return out\n",
    "\n",
    "def check_gene(genes, db):\n",
    "    genelist =  str(genes).split(',')\n",
    "    match = [g for g in genelist if g in db.keys()]\n",
    "    if match:\n",
    "        n, feat, hpo = pheno_db[match[0]]\n",
    "        return pd.Series([\"yes\", n, feat, hpo])\n",
    "    else:\n",
    "        return pd.Series([\"no\",0,'-','-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% mkdir {outdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read genomic data table generated by uploading HC-GATK raw VCF to http://wannovar.wglab.org/ \n",
    "data = pd.read_csv(wannovar_file, low_memory=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = pd.read_csv(intervar_file, low_memory=False, sep='\\t')\n",
    "inter_min = inter[[list(inter.columns)[i] for i in [0,1,2,3,4,12,13]]]\n",
    "inter_min.columns = [\"Chr\", \"Start\", \"End\", \"Ref\", \"Alt\" , \"ClinVar\", \"InterVar\"]\n",
    "clinvar_col = list(inter_min['ClinVar'].apply(lambda x: x.split(':')[1].strip()))\n",
    "intervar_col = list(inter_min['InterVar'].apply(lambda x: x.split(\":\")[1].split(\"P\")[0].strip()))\n",
    "\n",
    "inter_def = inter_min.iloc[:,0:5]\n",
    "inter_def['ClinVar'] = clinvar_col\n",
    "inter_def['ACMG_InterVar'] = intervar_col\n",
    "del inter\n",
    "del inter_min\n",
    "del clinvar_col\n",
    "del intervar_col\n",
    "\n",
    "clinical = inter_def.drop_duplicates()\n",
    "del inter_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data.merge(clinical, how='left', on=list(clinical.columns)[:-2])\n",
    "del data\n",
    "del clinical\n",
    "data = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add MIM phenotypes info\n",
    "pheno_0 = pd.read_csv(phenotypes_db, header=None, sep='\\t')\n",
    "pheno_0.columns = ['Gene.refgene','Phenotypes']\n",
    "pheno_1 = pheno_0.dropna()\n",
    "phenodbase = dict(list(pheno_1.apply(pheno_dic, axis=1)))\n",
    "data[\"Phenotypes\"] = data['Gene.refGene'].apply(get_pheno, phenodb=phenodbase)\n",
    "\n",
    "del pheno_0\n",
    "del pheno_1\n",
    "del phenotypes_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add MIM gene info\n",
    "omim = pd.read_csv(mim2gene_db, low_memory=False, header=None, sep='\\t')\n",
    "omim.columns = ['mim', 'Gene.refGene']\n",
    "weblinks = omim.mim.apply(lambda x: '=HYPERLINK(\"https://www.omim.org/entry/%s\", \"%s\")' % (str(x), str(x)))\n",
    "omim['mim'] = weblinks\n",
    "data_2 = pd.merge(data, omim, how = 'left')\n",
    "\n",
    "del omim\n",
    "del mim2gene_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add pLI gene info\n",
    "pli = pd.read_csv(pLI_db, low_memory=False, sep='\\t')\n",
    "pli.columns = ['Gene.refGene', 'pLI']\n",
    "data_3 = pd.merge(data_2, pli, how = 'left')\n",
    "\n",
    "del pli\n",
    "del pLI_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cleaner columns to data table \n",
    "del data\n",
    "del data_2\n",
    "data = data_3\n",
    "\n",
    "data[\"Genotype\"] = data[\"Otherinfo.12\"].apply(split_format, n=0)\n",
    "data[\"Genotype.qual\"] = data[\"Otherinfo.12\"].apply(split_format, n=3)\n",
    "data[\"Depth\"] = data[\"Otherinfo.12\"].apply(split_format, n=2)\n",
    "data[\"Zygosity\"] = data['Genotype'].apply(zygosity)\n",
    "data[\"Allele_counts\"] = data[\"Otherinfo.12\"].apply(split_format, n=1)\n",
    "data[\"Site.qual\"] = data[\"Otherinfo.8\"]\n",
    "data[\"strand.FS\"] = data['Otherinfo.10'].apply(get_info, val='FS')\n",
    "data[\"strand.OR\"] = data['Otherinfo.10'].apply(get_info, val='SOR')\n",
    "\n",
    "data[\"CHROM\"] = data[\"Otherinfo.3\"]\n",
    "data[\"POS\"] = data[\"Otherinfo.4\"]\n",
    "data[\"REF\"] = data[\"Otherinfo.6\"]\n",
    "data[\"ALT\"] = data[\"Otherinfo.7\"]\n",
    "\n",
    "data['Effect'] = data['GeneDetail.refGene'].str.cat(data['AAChange.refGene'], sep =\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Snp = []\n",
    "for snp, chrom, pos, ref,alt in data[['avsnp147', 'CHROM','POS','REF','ALT']].values:\n",
    "    if snp!='.':\n",
    "        Snp.append('=HYPERLINK(\"https://www.ncbi.nlm.nih.gov/snp/%s\", \"%s\")' % (snp, snp))\n",
    "    else:\n",
    "        loc = \"%s:%s%s>%s\" % (chrom,pos,ref,alt)\n",
    "        Snp.append('=HYPERLINK(\"https://gnomad.broadinstitute.org/region/%s-%s-%s\", \"%s\")' % (chrom,pos,pos,loc))\n",
    "\n",
    "data['dbSNP147'] = Snp       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dbSNP to weblink\n",
    "#snp = data['avsnp147'].apply(lambda x: '=HYPERLINK(\"https://www.ncbi.nlm.nih.gov/snp/%s\", \"%s\")' % (str(x), str(x)))\n",
    "#data['dbSNP147'] = snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract frequency databases column names\n",
    "freq_cols_tmp = [col for col in list(data.columns) if col.endswith(\"_ALL\") or col.endswith(\"_all\")]\n",
    "freq_cols = [freq_cols_tmp[i] for i in [0,2,3,4]]\n",
    "\n",
    "# Extract Clinvar column\n",
    "#clinVar_cols = [col for col in list(data.columns) if col.startswith(\"ClinVar\")][1:]\n",
    "clinVar_cols = [\"CLNSIG\"]\n",
    "\n",
    "# Define impact criterias to be considered\n",
    "impact_cols = [\"SIFT_pred\", \"Polyphen2_HDIV_pred\", \"Polyphen2_HVAR_pred\", \n",
    "               \"MutationTaster_pred\", \"MutationAssessor_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_a = ~( data[\"ExonicFunc.refGene\"].isin([\"synonymous SNV\"]) \n",
    "                | data[\"Func.refGene\"].isin([\"intergenic\"])\n",
    "                | data[\"Func.refGene\"].str.contains(\"intronic\")\n",
    "                | data[\"Func.refGene\"].str.contains(\"stream\"))\n",
    "\n",
    "filter_b = data[\"Site.qual\"]>=30\n",
    "filter_c = data[\"Depth\"]>=10\n",
    "filter_d = data[\"strand.FS\"]<=200\n",
    "filter_e = data[\"strand.OR\"]<=10\n",
    "\n",
    "#reject FS>60, SOR >3 for SNPs and FS>200, SOR>10 for indels.\n",
    "\n",
    "filter_1 = filter_a & filter_b & filter_c & filter_d & filter_d\n",
    "del filter_a\n",
    "del filter_b\n",
    "del filter_c\n",
    "del filter_d\n",
    "del filter_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_freq = data[freq_cols].apply(freq_check, axis=1, NotANum=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_effect = data[impact_cols].apply(impact_check, axis=1, NotANum=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['db_AF'] = allele_freq\n",
    "data['pred_effect'] = pred_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was gene suggested by Phenotips?\n",
    "phenotips = pd.read_csv(phenotips_file, low_memory=False, sep='\\t')\n",
    "phenotips.columns = ['Gene.refGene', 'GeneID', 'Phenotips_Score', 'Features','HPOs']\n",
    "\n",
    "DB = [tuple(x) for x in phenotips[['Gene.refGene','Phenotips_Score', 'Features','HPOs']].values]\n",
    "pheno_db = dict([(x[0], x[1:4]) for x in DB])\n",
    "\n",
    "phenotype = data['Gene.refGene'].apply(check_gene, db=pheno_db)\n",
    "phenotype.columns = ['in_phenotips', 'n_phenotips', 'feat_phenotips', 'HPO_terms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.concat([data,phenotype], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sophia = pd.read_excel(open(sophia_file))\n",
    "sophia_cols = ['chromosome','genome_position','ref','alt','Category','ACMG value']\n",
    "sophia_labs = ['CHROM','POS','REF','ALT','Category_sophia','ACMG_sophia']\n",
    "sophia_short = sophia[sophia_cols]\n",
    "sophia_short.columns = sophia_labs\n",
    "del sophia\n",
    "sophia = sophia_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.merge(data2.astype(str), sophia.astype(str), how='left').fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cols = [\"dbSNP147\",\"Zygosity\", \"Allele_counts\", \"db_AF\", \"pred_effect\",\n",
    "            \"Func.refGene\", \"ExonicFunc.refGene\", \"Gene.refGene\", \n",
    "            \"Effect\", \"Phenotypes\", \"mim\", \"pLI\", \"CADD_phred\",\"ClinVar\", \"ACMG_InterVar\",\n",
    "            \"Category_sophia\",\"ACMG_sophia\"] + list(phenotype.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = data3[filter_1][out_cols]\n",
    "data4.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = {'Pathogenic':1000, 'Likely pathogenic':500, 'Uncertain significance':100, 'A':1000, 'B':500, 'C':100, '3':100, '4':500, '5':1000}\n",
    "score = []\n",
    "for array in data4[['ACMG_InterVar', 'ACMG_sophia', 'Category_sophia', 'n_phenotips']].values:\n",
    "    total = 0\n",
    "    if int(array[3]) > 0:\n",
    "        n = int(array[3])\n",
    "    else:\n",
    "        n = 1     \n",
    "    for v in array[:3]:\n",
    "        try:\n",
    "            total += t[v]\n",
    "        except:\n",
    "            total += 0\n",
    "    score.append(total*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4['score'] = score\n",
    "data4.sort_values(by=['score','n_phenotips'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(os.path.expanduser(outdir + prefix + \"_\" + timestamp + \".xlsx\"))\n",
    "data4.to_excel(writer, prefix, index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acmg = {'Benign': 1, 'Likely benign': 2, 'Uncertain significance': 3, 'Likely pathogenic' : 4, 'Pathogenic' : 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_acmg = data3[(data3['ACMG_sophia'] !='-') & (data3['ACMG_InterVar'] != '')][['ACMG_InterVar','ACMG_sophia']].apply(lambda x: pd.Series([ acmg[x[0]], x[1] ]),axis=1).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Identity between Intervar y Sophia Genetics for ACMG classification\n",
    "sum(compare_acmg[0] == compare_acmg[1])/float(len(compare_acmg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = os.path.expanduser(outdir + prefix + \"_\" + timestamp + \".ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%notebook -e $nb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
